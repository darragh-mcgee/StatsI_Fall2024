library(tidyr)
.libPaths()
.libPaths()
install.packages('IRkernel')
IRkernel::installspec()
install.packages('IRkernel')
IRkernel::installspec(user = FALSE)
# Exercise 3:
set.seed(2024)
n <- 200
m <- 1000
mat <- matrix(rnorm(m * n, mean = 20, sd = 3), nrow = 200)
# For simplicity, let's assume that assignment to
# control and experimental groups is always the same.
grp <- rep(0:1, times = 100)
# Calculate t-statstics for each of the experiments (taking input )
calculate_t_statistics <- function(mat, grp) {
# Create an empty vector that can store the t-statstic results for each experiment.
# The number of experiments is equal to the number of columns in the matrix,
# so numeric(ncol()) is used to create a numeric vector the same length as the
# number of experiments.
t_statistics_vector <- numeric(ncol(mat))
# A for loop is used to loop through each individual column of the matrix
# that holds an experiment.
for (i in 1:ncol(mat)) {
# The grp vector identifies whether each individual aligns with the
# experiment or the control.
# Split the Data by Each Group (i.e. Experiment and Control)
# Control Group has been coded as 0.
# Experiment Group has been coded as 1.
# Extract the values for the experimental group (by subsetting the matrix to
# specifically show the rows including 1 (i.e. experimental group))
experimental_group <- mat[grp == 1, i]
# Repeat process for the control group (by subsetting the matrix to
# specifically show the rows including 0)
control_group <- mat[grp == 0, i]
# Use the in-built t test function in R to compare the means of both extracted
# groups
t_statistic_result <- t.test(experimental_group, control_group)
# Exercise 3:
set.seed(2024)
n <- 200
m <- 1000
mat <- matrix(rnorm(m * n, mean = 20, sd = 3), nrow = 200)
# For simplicity, let's assume that assignment to
# control and experimental groups is always the same.
grp <- rep(0:1, times = 100)
# Calculate t-statstics for each of the experiments (taking input )
calculate_t_statistic <- function(mat, grp) {
# Create an empty vector that can store the t-statstic results for each experiment.
# The number of experiments is equal to the number of columns in the matrix,
# so numeric(ncol()) is used to create a numeric vector the same length as the
# number of experiments.
t_statistic_vector <- numeric(ncol(mat))
# A for loop is used to loop through each individual column of the matrix
# that holds an experiment.
for (i in 1:ncol(mat)) {
# The grp vector identifies whether each individual aligns with the
# experiment or the control.
# Split the Data by Each Group (i.e. Experiment and Control)
# Control Group has been coded as 0.
# Experiment Group has been coded as 1.
# Extract the values for the experimental group (by subsetting the matrix to
# specifically show the rows including 1 (i.e. experimental group))
experimental_group <- mat[grp == 1, i]
# Repeat process for the control group (by subsetting the matrix to
# specifically show the rows including 0)
control_group <- mat[grp == 0, i]
# Use the in-built t test function in R to compare the means of both extracted
# groups
t_statistic_results <- t.test(experimental_group, control_group)
# Store the results from the t statistic tests into the empty vector created.
t_statistic_vector[i] <- t_statistic_results$statistic
# all i need are t stats here
# going to take the t stats from what returns from the tstat and put it in the tstats vector
t_statistic_vector[i] <- t_result$statistic
# Return the vector of t-statistics for each experiment
return(t_statistic_vector)
# Exercise 3:
set.seed(2024)
n <- 200
m <- 1000
mat <- matrix(rnorm(m * n, mean = 20, sd = 3), nrow = 200)
# For simplicity, let's assume that assignment to
# control and experimental groups is always the same.
grp <- rep(0:1, times = 100)
# Calculate t-statstics for each of the experiments (taking input )
calculate_t_statistic <- function(mat, grp) {
# Create an empty vector that can store the t-statstic results for each experiment.
# The number of experiments is equal to the number of columns in the matrix,
# so numeric(ncol()) is used to create a numeric vector the same length as the
# number of experiments.
t_statistic_vector <- numeric(ncol(mat))
# A for loop is used to loop through each individual column of the matrix
# that holds an experiment.
for (i in 1:ncol(mat)) {
# The grp vector identifies whether each individual aligns with the
# experiment or the control.
# Split the Data by Each Group (i.e. Experiment and Control)
# Control Group has been coded as 0.
# Experiment Group has been coded as 1.
# Extract the values for the experimental group (by subsetting the matrix to
# specifically show the rows including 1 (i.e. experimental group))
experimental_group <- mat[grp == 1, i]
# Repeat process for the control group (by subsetting the matrix to
# specifically show the rows including 0)
control_group <- mat[grp == 0, i]
# Use the in-built t test function in R to compare the means of both extracted
# groups
t_statistic_results <- t.test(experimental_group, control_group)
# Store the results from the t statistic tests into the empty vector created.
t_statistic_vector[i] <- t_statistic_results$statistic
# all i need are t stats here
# going to take the t stats from what returns from the tstat and put it in the tstats vector
t_statistic_vector[i] <- t_result$statistic
}
# Return the vector of t-statistics for each experiment
return(t_statistic_vector)
}
t_statistic_vector <- calculate_t_statistics(mat, grp)
print(t_statistic_vector)
# Exercise 3:
set.seed(2024)
n <- 200
m <- 1000
mat <- matrix(rnorm(m * n, mean = 20, sd = 3), nrow = 200)
# For simplicity, let's assume that assignment to
# control and experimental groups is always the same.
grp <- rep(0:1, times = 100)
# Calculate t-statstics for each of the experiments (taking input )
calculate_t_statistic <- function(mat, grp) {
# Create an empty vector that can store the t-statstic results for each experiment.
# The number of experiments is equal to the number of columns in the matrix,
# so numeric(ncol()) is used to create a numeric vector the same length as the
# number of experiments.
t_statistic_vector <- numeric(ncol(mat))
# A for loop is used to loop through each individual column of the matrix
# that holds an experiment.
for (i in 1:ncol(mat)) {
# The grp vector identifies whether each individual aligns with the
# experiment or the control.
# Split the Data by Each Group (i.e. Experiment and Control)
# Control Group has been coded as 0.
# Experiment Group has been coded as 1.
# Extract the values for the experimental group (by subsetting the matrix to
# specifically show the rows including 1 (i.e. experimental group))
experimental_group <- mat[grp == 1, i]
# Repeat process for the control group (by subsetting the matrix to
# specifically show the rows including 0)
control_group <- mat[grp == 0, i]
# Use the in-built t test function in R to compare the means of both extracted
# groups
t_statistic_results <- t.test(experimental_group, control_group)
# Store the results from the t statistic tests into the empty vector created.
t_statistic_vector[i] <- t_statistic_results$statistic
# all i need are t stats here
# going to take the t stats from what returns from the tstat and put it in the tstats vector
t_statistic_vector[i] <- t_result$statistic
}
# Return the vector of t-statistics for each experiment
return(t_statistic_vector)
}
t_statistic_vector <- calculate_t_statistics(mat, grp)
# Exercise 3:
set.seed(2024)
n <- 200
m <- 1000
mat <- matrix(rnorm(m * n, mean = 20, sd = 3), nrow = 200)
# For simplicity, let's assume that assignment to
# control and experimental groups is always the same.
grp <- rep(0:1, times = 100)
# Createa a function to calculate and store t-statstics for each of the experiments
calculate_t_statistics <- function(mat, grp) {
# Create an empty vector that can store the t-statstic results for each experiment.
# The number of experiments is equal to the number of columns in the matrix,
# so numeric(ncol()) is used to create a numeric vector the same length as the
# number of experiments.
t_statistic_vector <- numeric(ncol(mat))
# A for loop is used to loop through each individual column of the matrix
# that holds an experiment.
for (i in 1:ncol(mat)) {
# The grp vector identifies whether each individual aligns with the
# experiment or the control.
# Split the Data by Each Group (i.e. Experiment and Control)
# Control Group has been coded as 0.
# Experiment Group has been coded as 1.
# Extract the values for the experimental group (by subsetting the matrix to
# specifically show the rows including 1 (i.e. experimental group))
experimental_group <- mat[grp == 1, i]
# Repeat process for the control group (by subsetting the matrix to
# specifically show the rows including 0)
control_group <- mat[grp == 0, i]
# Use the in-built t test function in R to compare the means of both extracted
# groups
t_statistic_results <- t.test(experimental_group, control_group)
# Store the results from the t statistic tests into the empty vector created.
t_statistic_vector[i] <- t_statistic_results$statistic
# Return the vector of t-statistics for each experiment
return(t_statistic_vector)
}
# Call the function
t_statistic_vector <- calculate_t_statistics(mat, grp)
print(t_statistic_vector)
# Exercise 3:
set.seed(2024)
n <- 200
m <- 1000
mat <- matrix(rnorm(m * n, mean = 20, sd = 3), nrow = 200)
# For simplicity, let's assume that assignment to
# control and experimental groups is always the same.
grp <- rep(0:1, times = 100)
# Createa a function to calculate and store t-statstics for each of the experiments
calculate_t_statistics <- function(mat, grp) {
# Create an empty vector that can store the t-statstic results for each experiment.
# The number of experiments is equal to the number of columns in the matrix,
# so numeric(ncol()) is used to create a numeric vector the same length as the
# number of experiments.
t_statistic_vector <- numeric(ncol(mat))
# A for loop is used to loop through each individual column of the matrix
# that holds an experiment.
for (i in 1:ncol(mat)) {
# The grp vector identifies whether each individual aligns with the
# experiment or the control.
# Split the Data by Each Group (i.e. Experiment and Control)
# Control Group has been coded as 0.
# Experiment Group has been coded as 1.
# Extract the values for the experimental group (by subsetting the matrix to
# specifically show the rows including 1 (i.e. experimental group))
experimental_group <- mat[grp == 1, i]
# Repeat process for the control group (by subsetting the matrix to
# specifically show the rows including 0)
control_group <- mat[grp == 0, i]
# Use the in-built t test function in R to compare the means of both extracted
# groups
t_statistic_results <- t.test(experimental_group, control_group)
# Store the results from the t statistic tests into the empty vector created.
t_statistic_vector[i] <- t_statistic_results$statistic
# Return the vector of t-statistics for each experiment
return(t_statistic_vector)
}
# Call the function
t_statistic_vector <- calculate_t_statistics(mat, grp)
print(t_statistic_vector)
source("~/.active-rstudio-document")
# Exercise 3:
set.seed(2024)
n <- 200
m <- 1000
mat <- matrix(rnorm(m * n, mean = 20, sd = 3), nrow = 200)
# For simplicity, let's assume that assignment to
# control and experimental groups is always the same.
grp <- rep(0:1, times = 100)
# Createa a function to calculate and store t-statstics for each of the experiments
calculate_t_statistics <- function(mat, grp) {
# Create an empty vector that can store the t-statstic results for each experiment.
# The number of experiments is equal to the number of columns in the matrix,
# so numeric(ncol()) is used to create a numeric vector the same length as the
# number of experiments.
t_statistic_vector <- numeric(ncol(mat))
# A for loop is used to loop through each individual column of the matrix
# that holds an experiment.
for (i in 1:ncol(mat)) {
# The grp vector identifies whether each individual aligns with the
# experiment or the control.
# Split the Data by Each Group (i.e. Experiment and Control)
# Control Group has been coded as 0.
# Experiment Group has been coded as 1.
# Extract the values for the experimental group (by subsetting the matrix to
# specifically show the rows including 1 (i.e. experimental group))
experimental_group <- mat[grp == 1, i]
# Repeat process for the control group (by subsetting the matrix to
# specifically show the rows including 0)
control_group <- mat[grp == 0, i]
# Use the in-built t test function in R to compare the means of both extracted
# groups
t_statistic_results <- t.test(experimental_group, control_group)
# Store the results from the t statistic tests into the empty vector created.
t_statistic_vector[i] <- t_statistic_results$statistic
}
# Return the vector of t-statistics for each experiment
return(t_statistic_vector)
}
# Call the function
t_statistic_vector <- calculate_t_statistics(mat, grp)
print(t_statistic_vector)
# Exercise 3:
set.seed(2024)
n <- 200
m <- 1000
mat <- matrix(rnorm(m * n, mean = 20, sd = 3), nrow = 200)
# For simplicity, let's assume that assignment to
# control and experimental groups is always the same.
grp <- rep(0:1, times = 100)
# Createa a function to calculate and store t-statstics for each of the experiments
calculate_t_statistics <- function(mat, grp) {
# Create an empty vector that can store the t-statstic results for each experiment.
# The number of experiments is equal to the number of columns in the matrix,
# so numeric(ncol()) is used to create a numeric vector the same length as the
# number of experiments.
t_statistic_vector <- numeric(ncol(mat))
# A for loop is used to loop through each individual column of the matrix
# that holds an experiment.
for (i in 1:ncol(mat)) {
# The grp vector identifies whether each individual aligns with the
# experiment or the control.
# Split the Data by Each Group (i.e. Experiment and Control)
# Control Group has been coded as 0.
# Experiment Group has been coded as 1.
# Extract the values for the experimental group (by subsetting the matrix to
# specifically show the rows including 1 (i.e. experimental group))
experimental_group <- mat[grp == 1, i]
# Repeat process for the control group (by subsetting the matrix to
# specifically show the rows including 0)
control_group <- mat[grp == 0, i]
# Use the in-built t test function in R to compare the means of both extracted
# groups
t_statistic_results <- t.test(experimental_group, control_group)
# Store the results from the t statistic tests into the empty vector created.
t_statistic_vector[i] <- t_statistic_results$statistic
}
# Return the vector of t-statistics for each experiment
return(t_statistic_vector)
}
# Call the function
t_statistic_vector <- calculate_t_statistics(mat, grp)
print(t_statistic_vector)
# The header in this dataset consists of 2 rows (i.e. a composite header).
# The first row contains the question numbers and the second row contains the
# detailed questions asked.
# Read the first row only
questions <- readr::read_csv("C:/Users/darra/OneDrive/Desktop/Postgraduate Course/Programming/kaggle_survey_2022_responses.csv", n_max = 1)
# Load the full dataset using the extracted column headers (question numbers),
# skipping the detailed questions.
kaggle2022 <- readr::read_csv("C:/Users/darra/OneDrive/Desktop/Postgraduate Course/Programming/kaggle_survey_2022_responses.csv", col_names = names(questions), skip = 2)
# Select the relevant columns for analysis (i.e all columns related to question 12).
new_data <- dplyr::select(kaggle2022, Q12_1:Q12_15)
new_data
# Create a vector including the names of the relevant programming languages that correspond to each sub-question
# (for ease of reference when reading the percentages).
programming_languages <- c("Python", "R", "SQL", "C", "C#", "C++", "Java",
"JavaScript", "Bash", "PHP", "MATLAB",
"Julia", "Go", "None", "Other")
# Rename the columns in new_data using the vector of programming languages
colnames(new_data) <- programming_languages
# Pivot the data into a longer format to facilitate analysis
longer_format <- tidyr::pivot_longer(new_data, cols = everything(),
names_to = "Programming_Language",
values_to = "Answer")
# Replace all NA values in the Answer column with 0 and all other values with 1.
longer_format$Answer <- ifelse(is.na(longer_format$Answer), "0", "1")
# Count how many respondents use each programming language.
programming_language_counts <- dplyr::count(longer_format, Programming_Language, Answer)
programming_language_counts
# Calculate the percentage of respondents who use each programming language and
# sort the percentages in descending order.
# %>% used to create chain data transformations without needing intermediate variables
sorted_programming_language_percentages <- programming_language_counts %>%
filter(Answer == "1") %>%
dplyr::mutate(Percentage = n / sum(n) * 100) %>%
dplyr::arrange(desc(Percentage))
IRkernel::installspec(user = FALSE)
install.packages('IRkernel')
# Set Working Directory
setwd("C:/Users/darra/OneDrive/Documents/GitHub/StatsI_Fall2024/problemSets/PS03/my_answers")
# Read in Data
inc.sub <- read.csv("https://raw.githubusercontent.com/ASDS-TCD/StatsI_Fall2024/main/datasets/incumbents_subset.csv")
str(inc.sub)
# Assumptions Underlying Linear Regression:
# Linear Relationship: There is a linear relationship between the outcome and
# explanatory variables.
# Independence of Errors: The errors (residuals) are independent of each other.
# Normality of errors: For any given value of the explanatory variable, the
# errors (residuals) are assumed to follow a normal distribution.
# Constant variance (Homoscedasticity): The variance of the errors is constant
# across all values of the explanatory variable
# No Perfect Multi-Collinearity: The explanatory variables should not be perfectly
# correlated with each other.
# Question 1:
# Part 1:
model_1 <- lm(voteshare ~ difflog, data = inc.sub)
summary(model_1)
# The intercept of 0.579031 indicates that when the logarithmic difference in campaign
# spending between the incumbent and challenger is zero, the incumbent's
# vote share is predicted to be 57.9%.
# There is a positive, statistically relevant relationship between the log-transformed difference in
# campaign spending (Incumbent - Challenger) and the incumbent's vote share,
# with a p-value of less than 0.001 (indicated by three stars in the regression table).
# Specifically, a one-unit increase in the logged difference in campaign spending is
# associated with an average increase of 0.04 (or 4%) in the incumbent’s vote share.
# Part 2:
# Plotting the Relationship:
png("Figure_1_1.png", width = 1500, height = 950, res = 200)
plot(voteshare ~ difflog, data = inc.sub,
xlab = "Difference in Campaign Spending (Incumbent - Challenger)",
ylab = "Incumbent Vote Share",
main = "Scatterplot of Relationship between Campaign Spending Difference
and Incumbent Vote Share")
abline(model_1, col = "blue", lwd = 1)
dev.off()
# Part 3:
# Save the Residuals as a Separate Object
residuals.model.1 <- residuals(model_1)
# Part 4:
# Write the Prediction Equation
# voteshare = 0.57903 + 0.4167*difflog
# Question 2:
# Part A:
model_2 <- lm(presvote ~ difflog, data = inc.sub)
summary(model_2)
# The intercept of 0.507583 indicates that when the logarithmic difference in campaign
# spending between the incumbent and challenger is zero, the vote share of the
# presidential candidate of the incumbent is predicted to be 50.758%.
# There is a positive, statistically relevant relationship between the log-transformed difference in
# campaign spending (Incumbent - Challenger) and the vote share of the presidential
# candidate of the incumbent, with a p-value of less than 0.001
# (indicated by three stars in the regression table). Specifically, a one-unit
# increase in the logged difference in campaign spending is associated with an average
# increase of 0.0238 (or 2.38%) in the presidential candidate of the incumbent's
# vote share.
# Part B:
# Plot the Relationship:
png("Figure_2_1.png", width = 1500, height = 950, res = 200)
plot(presvote ~ difflog, data = inc.sub,
ylab = "Vote Share of Presidential Candidate of Incumbent",
xlab = "Difference in Campaign Spending (Incumbent - Challenger)",
main = "Scatterplot of Relationship betwen Campaign Spending
Difference and Vote Share of Presidential Candidate of Incumbent")
abline(model_2, col = "green", lwd = 1)
dev.off()
# Part C:
residuals.model.2 <- residuals(model_2)
# Part D:
# Write the Prediction Equation
# presvote = 0.50758 + 0.0238*difflog
# Question 3:
# Part A:
model_3 <- lm(voteshare ~ presvote, data = inc.sub)
summary(model_3)
# The intercept of 0.4413 indicates that when the vote share of the incumbent’s
# presidential candidate is zero, the predicted vote share of the incumbent is 44.13%
# There is a positive, statistically relevant relationship between the vote share of
# the incumbent’s presidential candidate and the incumbent’s vote share, with a
# p-value of less than 0.001 (indicated by three stars in the regression table).
# Specifically, a one-unit increase in the vote share of the incumbent’s presidential
# candidate is associated with an average increase of 0.388 (or 38.8 percentage points)
# in the incumbent’s vote share.
# Part B:
# Plot the Relationship:
png("Figure_3_1.png", width = 1500, height = 950, res = 200)
plot(voteshare ~ presvote, data = inc.sub,
xlab = "Vote Share of Presidential Candidate of Incumbent",
ylab = "Incumbent Vote Share",
main = "Scatterplot of Relationship between Vote Share of
Presidential Candidate of Incumbent and Incumbent Vote Share")
abline(model_3, col = "red", lwd = 1)
dev.off()
# Part C:
# Write the Prediction Equation
# voteshare = 0.4413 + 0.3880*presvote
# Question 4:
# Part A:
model_4 <- lm(residuals.model.1 ~ residuals.model.2)
summary(model_4)
# There is a positive, statistically relevant relationship between the
# residuals from model 1 and model 2, with a p-value of less than 0.001
# (indicated by three stars in the regression table).Specifically, a one-unit
# increase in the residual (error) from model 2 is associated with an average
# increase of 0.2569 in the residual (error) from model 1.
# Part B:
# Plot the Relationship:
png("Figure_4_1.png", width = 1500, height = 950, res = 200)
# Adjust Margins to Prevent Cutting Off Label
par(mar = c(5, 7, 5, 3))
plot(residuals.model.1 ~ residuals.model.2, data = inc.sub,
xlab = "Variation in Presidential Candidate's Vote Share
Not Explained by Campaign Spending",
ylab = "Variation in Incumbent's Vote Share
Not Explained by Campaign Spending",
main = "Scatterplot of Unexplained Variation in Incumbent Vote Share
versus Unexplained Variation in Presidential Candidate's Vote Share")
abline(model_4, col = "purple", lwd = 1)
dev.off()
# Part C:
# Write the Prediction Equation
# residuals.model.1 = 0 + 0.2569*residuals.model.2
# Question 5:
# Part A:
model_5 <- lm(voteshare ~ difflog + presvote, data = inc.sub)
summary(model_5)
# The intercept of 0.4486 represents the average predicted vote share of the incumbent
# when both difflog and presvote are zero.
# There is a positive, statistically relevant relationship between the
# log-transformed difference in campaign spending and the incumbent’s vote share.
# Specifically, a one-unit increase in difflog is associated with an average increase of
# 3.55 percentage points in the incumbent’s vote share, holding presvote constant.
# There is also a positive, statistically relevant relationship between the
# presidential candidate’s vote share (presvote) and the incumbent’s vote share.
# Specifically, a one-unit increase in presvote is associated with an average increase
# of 25.69 percentage points in the incumbent’s vote share, holding difflog constant.
# The multivariate regression model explains approximately 44.96% of the variation
# in voteshare, as indicated by the Multiple R-squared of 0.4496, suggesting a moderate fit.
# Part B:
# Write the Prediction Equation
# voteshare = 0.44864 + 0.03554*difflog + 0.25688*presvote
# Part C:
# The coefficients for residuals.model.2 in Model 4 and presvote in Model 5 are
# the same because they are both measuring the same underlying relationship,
# i.e., the co-variation between the presidential candidate’s vote share
# (presvote) and the incumbent’s vote share (voteshare) that is not explained by
# the differences in campaign spending. In Model 4, this relationship is
# measured through the residuals (unexplained variation),
# while Model 5 captures the partial effect of presvote directly.
